# coding: utf-8
"""
This module contains a PyLucene filter that converts tokens to their
phonetic representation.
"""

__author__ = "Caleb"
__version__ = "0.1"
__status__ = "Prototype"

__all__ = ['SoundexFilter']

import sys

import fuzzy
import lucene

def main(argv):
	import argparse
	
	parser = argparse.ArgumentParser(prog=argv[0])
	parser.add_argument('string', metavar="string", help="The string to tokenize.")
	parser.add_argument('-v', '--verbose', action='store_true', help="Print verbose output.")
	args = parser.parse_args(argv[1:])
	
	string = args.string
	verbose = args.verbose
	
	lucene.initVM()
	
	tokens = lucene.WhitespaceTokenizer(lucene.Version.LUCENE_CURRENT, lucene.StringReader(string))
	tee = lucene.TeeSinkTokenFilter(tokens)
	sinks = [tee.newSinkTokenStream() for i in xrange(3 if verbose else 1)]
	tee.consumeAllTokens()

	if verbose:
		print "Tokens"
		print "------"
		tokens = sinks.pop()
		term = tokens.addAttribute(lucene.TermAttribute.class_)
		while tokens.incrementToken():
			print "[%s]" % term.term(),
		print "\n"
		
	print "SoundexFilter"
	print "---------------------"
	if verbose:
		tokens = SoundexFilter(sinks.pop(), 6)
		term = tokens.addAttribute(lucene.TermAttribute.class_)
		while tokens.incrementToken():
			print "[%s]" % term.term(),
		print "\n  REPLACE"
	tokens = SoundexFilter(sinks.pop(), 6, replace=True)
	term = tokens.addAttribute(lucene.TermAttribute.class_)
	while tokens.incrementToken():
		print "[%s]" % term.term(),
	print
	
	return 0


class SoundexFilter(lucene.PythonTokenFilter):
	"""
	The ``SoundexFilter`` class is a PyLucene Filter that converts tokens
	to their phonetic representation using the Soundex algorithm.
	
	Instance Attribute:
	
	*offset* (``lucene.OffsetAttribute``) is used for accessing the offset
	of the token in the original un-tokenized string.
	
	*pos* (``lucene.PositionIncrementAttribute``) is used for accessing
	the position of a token relative to the previous token.
		
	*soundex* (``fuzzy.Soundex``) is the soundex instance.
	
	*term* (``lucene.TermAttribute``) is used for accessing the value of a
	token.
	"""
	
	def __init__(self, in_stream, length, replace=None):
		"""
		Initializes the ``SoundexFilter`` instance.
		
		*in_stream* (``lucene.PythonTokenStream``) is the token input stream.
		
		*length* (``int``) is the length of the soundex string.
		
		*replace* (``bool``) is whether tokens created by this filter should
		replace the encountered tokens (``True``), or if they should be
		combined (i.e., appended after) the encountered tokens. Default is
		``False``.
		"""
		self.soundex = None
		
		if not isinstance(length, int):
			raise TypeError("length:%r is not an ``int``." % length)
		elif length < 1:
			raise ValueError("length:%r must be greater than 0." % length)
		
		lucene.PythonTokenFilter.__init__(self, in_stream)
		term_attr = self.term = self.addAttribute(lucene.TermAttribute.class_)
		pos_attr = self.pos = self.addAttribute(lucene.PositionIncrementAttribute.class_)
		off_attr = self.offset = self.addAttribute(lucene.OffsetAttribute.class_)
		
		# Setup soundex.
		self.soundex = fuzzy.Soundex(length)
		
		# Get tokens.
		tokens = []
		while in_stream.incrementToken():
			tokens.append((
				term_attr.term(),
				pos_attr.getPositionIncrement(),
				off_attr.startOffset(),
				off_attr.endOffset()
			))
			
		# Filter tokens.
		tokens = self.filter(tokens, replace)
		
		# Setup token iterator.
		self.iter = iter(tokens)

	def filter(self, tokens, replace):
		"""
		Filters the tokens.
		
		*tokens* (``list``) the tokens (``str``).
		
		*replace* (``bool``) is whether tokens created by this filter should
		replace the encountered tokens (``True``), or if they should be
		combined (i.e., appended after) the encountered tokens. Default is
		``False``.
		
		Returns the filtered (``list``) tokens (``str``).
		"""
		soundex = self.soundex
		found = set(t[0] for t in tokens) if not replace else set()
		final = []
		for token in tokens:
			if not replace:
				# Since we are not supposed to replace tokens, append each token
				# before it is consumed.
				final.append(token)
			# Run token through soundex.
			result = soundex(token[0])
			if result and result not in found:
				found.add(result)
				final.append((result, token[1], token[2], token[3]))
		return final

	def incrementToken(self):
		"""
		This method sets an internal buffer with the current token each time
		it is called. NOTE: This method must be implemented by
		``lucene.PythonTokenFilter`` subclasses.
		
		Returns ``True`` if more tokens are available; otherwise, ``False``.
		"""
		try:
			val, pos, off_start, off_end = next(self.iter)
			self.term.setTermBuffer(val)
			self.pos.setPositionIncrement(pos)
			self.offset.setOffset(off_start, off_end)
		except StopIteration:
			return False
		return True
	
	
if __name__ == '__main__':
	sys.exit(main(sys.argv))
